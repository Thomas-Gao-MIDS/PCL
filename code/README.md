# Main notebooks
1. __PCL1__: Baseline models.
2. __PCL2.1__: Evaluates numbers of epochs to run, and fine-tuning RoBERTa model. Learned it takes more epochs to fine-tune than BERT because [CLS] was not pre-trained.
3. __PCL2.2__: Cleans code, train BERT model, examine using Integrated Gradients.
4. __PCL2.3__: Validates Integrated Gradients implementation with a simpler IMDB dataset.
5. __PCL2.4__: Upsample to train BERT model on more data.
6. __PCL3.*__: Idea is to highlight the PCL span to model, so it can better learn. Got hands on experience with span detection and multi-objective learning. However, due to time constraint, this is incomplete work.
