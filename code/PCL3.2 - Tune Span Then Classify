{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PCL3.2 - Tune Span Then Classify","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNIbt7K3VNiJOzKSs019I4c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"nvUG6vCAiW2t"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"-blBG8QyiE8h","executionInfo":{"status":"ok","timestamp":1648420915864,"user_tz":420,"elapsed":19153,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"d1d80b5d-3ae0-4a94-fbb3-e5703336e20f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/w266 project/dontpatronizeme/semeval-2022'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir('/content/drive/MyDrive/w266 project/dontpatronizeme/semeval-2022')\n","os.getcwd()"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yljEsQFtiZys","executionInfo":{"status":"ok","timestamp":1648420923843,"user_tz":420,"elapsed":7982,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"b55d31c4-b3f9-4cab-9de2-fd30d0c2f151"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 6.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 59.5 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 60.9 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 61.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.5 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import ast\n","import matplotlib.pyplot as plt\n","import random\n","\n","from sklearn.metrics import f1_score\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.backend import sparse_categorical_crossentropy\n","from tensorflow.keras.layers import Dense, Flatten\n","\n","import transformers\n","from transformers import BertTokenizer, TFBertModel, DistilBertTokenizer, TFDistilBertModel\n","\n","#import alibi\n","#from alibi.explainers import IntegratedGradients\n","\n","import logging\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.config.list_physical_devices('GPU')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X7ezem50id_w","executionInfo":{"status":"ok","timestamp":1648423706253,"user_tz":420,"elapsed":173,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"f1b2dc4a-c81e-4f52-b572-b308aa865755"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["# helper function to save predictions to an output file\n","def labels2file(p, outf_path):\n","\twith open(outf_path,'w') as outf:\n","\t\tfor pi in p:\n","\t\t\toutf.write(','.join([str(k) for k in pi])+'\\n')"],"metadata":{"id":"KMryzv-Pihct","executionInfo":{"status":"ok","timestamp":1648420933756,"user_tz":420,"elapsed":17,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Data"],"metadata":{"id":"8CWnhRgNikrg"}},{"cell_type":"markdown","source":["## Task 1 Data"],"metadata":{"id":"U3NKO07osgnZ"}},{"cell_type":"code","source":["from dont_patronize_me import DontPatronizeMe\n","dpm = DontPatronizeMe('data', 'TEST/task4_test.tsv')\n","dpm.load_task1()\n","dpm.load_task2(return_one_hot=True)\n","dpm.load_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_f1-RjiLilHs","executionInfo":{"status":"ok","timestamp":1648420943154,"user_tz":420,"elapsed":1824,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"8549bb64-d3da-4798-b186-618c97df1d84"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Map of label to numerical label:\n","{'Unbalanced_power_relations': 0, 'Shallow_solution': 1, 'Presupposition': 2, 'Authority_voice': 3, 'Metaphors': 4, 'Compassion': 5, 'The_poorer_the_merrier': 6}\n"]}]},{"cell_type":"code","source":["trids = pd.read_csv('practice splits/train_semeval_parids-labels.csv')\n","teids = pd.read_csv('practice splits/dev_semeval_parids-labels.csv') \n","trids.par_id = trids.par_id.astype(str)\n","teids.par_id = teids.par_id.astype(str)\n","print(trids.shape)\n","print(teids.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ebkYlrDi2yq","executionInfo":{"status":"ok","timestamp":1648420982789,"user_tz":420,"elapsed":889,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"1ce6b8ae-7e45-4f5e-93f5-80a55e2aaba0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(8375, 2)\n","(2094, 2)\n"]}]},{"cell_type":"code","source":["# Rebuild train set for Task 1\n","rows = [] # will contain par_id, label and text\n","for idx in range(len(trids)):  \n","  parid = trids.par_id[idx]\n","  #print(parid)\n","  # select row from original dataset to retrieve `text` and binary label\n","  text = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].text.values[0]\n","  label = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].label.values[0]\n","  rows.append({\n","      'par_id':parid,\n","      'text':text,\n","      'label':label\n","  })\n","\n","trdf1 = pd.DataFrame(rows)\n","\n","# Rebuild test set for Task 1\n","rows = [] # will contain par_id, label and text\n","for idx in range(len(teids)):  \n","  parid = teids.par_id[idx]\n","  #print(parid)\n","  # select row from original dataset\n","  text = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].text.values[0]\n","  label = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].label.values[0]\n","  rows.append({\n","      'par_id':parid,\n","      'text':text,\n","      'label':label\n","  })\n","\n","tedf1 = pd.DataFrame(rows)\n","\n","# downsample negative instances\n","pcldf = trdf1[trdf1.label==1]\n","npos = len(pcldf)\n","\n","training_set1 = pd.concat([pcldf,trdf1[trdf1.label==0][:npos*1]])\n","training_set1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"Mz3EgMtqjAsN","executionInfo":{"status":"ok","timestamp":1648422174438,"user_tz":420,"elapsed":26426,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"5d0d5c84-2851-4cf1-8ef8-f89321a46605"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     par_id                                               text  label\n","0      4341  The scheme saw an estimated 150,000 children f...      1\n","1      4136  Durban 's homeless communities reconciliation ...      1\n","2     10352  The next immediate problem that cropped up was...      1\n","3      8279  Far more important than the implications for t...      1\n","4      1164  To strengthen child-sensitive social protectio...      1\n","...     ...                                                ...    ...\n","1583    881  \"\"\" We will continue to support vulnerable peo...      0\n","1584    883  The Toronto Playground Association scored a fe...      0\n","1585    884  The Commons home affairs select committee said...      0\n","1586    885  Indian immigrants across the world are flockin...      0\n","1587    886  One of our clients , Deutsche Post AG , was ab...      0\n","\n","[1588 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-cc4fc711-ea28-4700-a673-fd732475a9c7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>par_id</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4341</td>\n","      <td>The scheme saw an estimated 150,000 children f...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4136</td>\n","      <td>Durban 's homeless communities reconciliation ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10352</td>\n","      <td>The next immediate problem that cropped up was...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8279</td>\n","      <td>Far more important than the implications for t...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1164</td>\n","      <td>To strengthen child-sensitive social protectio...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1583</th>\n","      <td>881</td>\n","      <td>\"\"\" We will continue to support vulnerable peo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1584</th>\n","      <td>883</td>\n","      <td>The Toronto Playground Association scored a fe...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1585</th>\n","      <td>884</td>\n","      <td>The Commons home affairs select committee said...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1586</th>\n","      <td>885</td>\n","      <td>Indian immigrants across the world are flockin...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1587</th>\n","      <td>886</td>\n","      <td>One of our clients , Deutsche Post AG , was ab...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1588 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc4fc711-ea28-4700-a673-fd732475a9c7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cc4fc711-ea28-4700-a673-fd732475a9c7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cc4fc711-ea28-4700-a673-fd732475a9c7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["training_set1.label.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ht8xO0pqjCtC","executionInfo":{"status":"ok","timestamp":1648422176933,"user_tz":420,"elapsed":156,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"395d6849-d650-417b-f451-cec4da32800c"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    794\n","0    794\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["## Span Data"],"metadata":{"id":"iQ9xBlf-pRFo"}},{"cell_type":"code","source":["par_ids = []\n","texts = []\n","starts = []\n","finishes = []\n","\n","with open (os.path.join('data/dontpatronizeme_categories.tsv')) as f:\n","  for line in f.readlines()[4:]:\n","    par_id=int(line.strip().split('\\t')[0])\n","    text=line.split('\\t')[2]#.lower()\n","    start=int(line.split('\\t')[5])\n","    finish=int(line.split('\\t')[6])\n","\n","    par_ids.append(par_id)\n","    texts.append(text)\n","    starts.append(start)\n","    finishes.append(finish)\n","\n","df_text = pd.DataFrame(list(zip(par_ids, texts, starts, finishes)), columns=['par_id', 'text', 'start', 'finish']).sort_values(['par_id', 'start']).drop_duplicates()\n","df_text.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"3VUiFwBDpNNK","executionInfo":{"status":"ok","timestamp":1648422648300,"user_tz":420,"elapsed":183,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"8399b5e5-62ef-4634-89f6-2f74d79b3c46"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      par_id                                               text  start  finish\n","2381      33  Arshad said that besides learning many new asp...    157     243\n","1232      34  Fast food employee who fed disabled man become...      0      67\n","2355      42  Vanessa had feelings of hopelessness in her fi...      0     182\n","868       77  In September , Major Nottle set off on foot fr...     15     128\n","869       77  In September , Major Nottle set off on foot fr...     28      71"],"text/html":["\n","  <div id=\"df-50067e66-c752-4bcb-ab52-62a7bfd8e4a7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>par_id</th>\n","      <th>text</th>\n","      <th>start</th>\n","      <th>finish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2381</th>\n","      <td>33</td>\n","      <td>Arshad said that besides learning many new asp...</td>\n","      <td>157</td>\n","      <td>243</td>\n","    </tr>\n","    <tr>\n","      <th>1232</th>\n","      <td>34</td>\n","      <td>Fast food employee who fed disabled man become...</td>\n","      <td>0</td>\n","      <td>67</td>\n","    </tr>\n","    <tr>\n","      <th>2355</th>\n","      <td>42</td>\n","      <td>Vanessa had feelings of hopelessness in her fi...</td>\n","      <td>0</td>\n","      <td>182</td>\n","    </tr>\n","    <tr>\n","      <th>868</th>\n","      <td>77</td>\n","      <td>In September , Major Nottle set off on foot fr...</td>\n","      <td>15</td>\n","      <td>128</td>\n","    </tr>\n","    <tr>\n","      <th>869</th>\n","      <td>77</td>\n","      <td>In September , Major Nottle set off on foot fr...</td>\n","      <td>28</td>\n","      <td>71</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50067e66-c752-4bcb-ab52-62a7bfd8e4a7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-50067e66-c752-4bcb-ab52-62a7bfd8e4a7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-50067e66-c752-4bcb-ab52-62a7bfd8e4a7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["prev_par_id = df_text.iloc[0, 0]\n","prev_text = df_text.iloc[0, 1]\n","cursor = 0\n","\n","par_ids = []\n","words = []\n","tags = []\n","\n","for _, row in df_text.iterrows():\n","  par_id=row[0]\n","  text=row[1]#.lower()\n","  start=row[2]\n","  finish=row[3]\n","\n","  # finish the previous paragraph\n","  if par_id != prev_par_id:\n","    words_o = prev_text[cursor:].split()\n","    for w in words_o:\n","      par_ids.append(prev_par_id)\n","      words.append(w)\n","      tags.append('O')\n","\n","    # update par_id, text, initialize cursor\n","    prev_par_id = par_id\n","    prev_text = text\n","    cursor = 0\n","\n","  # add non-PCL words\n","  if cursor < start:\n","    words_o = text[cursor:start].split()\n","    for w in words_o:\n","      par_ids.append(par_id)\n","      words.append(w)\n","      tags.append('O')\n","    cursor = start\n","\n","  # add PCL words\n","  if cursor >= start and cursor <= finish:\n","    words_bi = text[cursor:finish].split()\n","    for w in words_bi:\n","      par_ids.append(par_id)\n","      words.append(w)\n","      tags.append('I')\n","    cursor = finish\n","\n","words_o = prev_text[cursor:].split()\n","for w in words_o:\n","  par_ids.append(prev_par_id)\n","  words.append(w)\n","  tags.append('O')\n","        \n","df_words = pd.DataFrame(list(zip(par_ids, words, tags)), columns=['par_id', 'word', 'tag'])\n","df_words"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"XB0GLW7TpW7Q","executionInfo":{"status":"ok","timestamp":1648422658710,"user_tz":420,"elapsed":400,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"cd304c36-b872-4381-ada5-31e6afe18372"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       par_id      word tag\n","0          33    Arshad   O\n","1          33      said   O\n","2          33      that   O\n","3          33   besides   O\n","4          33  learning   O\n","...       ...       ...  ..\n","53961   10469         A   I\n","53962   10469      good   I\n","53963   10469       day   O\n","53964   10469         .   O\n","53965   10469       \"\"\"   O\n","\n","[53966 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-8d9c4768-80ce-4331-b900-956e405119a0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>par_id</th>\n","      <th>word</th>\n","      <th>tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>33</td>\n","      <td>Arshad</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>33</td>\n","      <td>said</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>33</td>\n","      <td>that</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>33</td>\n","      <td>besides</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>33</td>\n","      <td>learning</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>53961</th>\n","      <td>10469</td>\n","      <td>A</td>\n","      <td>I</td>\n","    </tr>\n","    <tr>\n","      <th>53962</th>\n","      <td>10469</td>\n","      <td>good</td>\n","      <td>I</td>\n","    </tr>\n","    <tr>\n","      <th>53963</th>\n","      <td>10469</td>\n","      <td>day</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>53964</th>\n","      <td>10469</td>\n","      <td>.</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>53965</th>\n","      <td>10469</td>\n","      <td>\"\"\"</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>53966 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d9c4768-80ce-4331-b900-956e405119a0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8d9c4768-80ce-4331-b900-956e405119a0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8d9c4768-80ce-4331-b900-956e405119a0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["#df_words_train = df_words[df_words['par_id'].isin([int(par_id) for par_id in trids.par_id])]\n","df_words_train = df_words[df_words['par_id'].isin([int(par_id) for par_id in training_set1.par_id])]\n","df_words_test = df_words[df_words['par_id'].isin([int(par_id) for par_id in teids.par_id])]\n","print(df_words_train.shape)\n","print(df_words_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Si6DXBcpkeB","executionInfo":{"status":"ok","timestamp":1648423261539,"user_tz":420,"elapsed":5,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"86cb9ea9-32f4-45a7-e1d7-e2d9afb2b99f"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["(43075, 3)\n","(10891, 3)\n"]}]},{"cell_type":"code","source":["max_length = 50"],"metadata":{"id":"iQMU1ej-stcN","executionInfo":{"status":"ok","timestamp":1648423525845,"user_tz":420,"elapsed":186,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["## Span Input Gen"],"metadata":{"id":"irXWqtq0sll7"}},{"cell_type":"code","source":["def addWord(word, tag):\n","    \"\"\"\n","    Convert a word into a word token and add supplied tags. Note that the word can be  \n","    tokenized to two or more tokens. Correspondingly, we add - for now - custom 'X' tokens to the labels in order to \n","    maintain the 1:1 mappings between word tokens and labels.\n","    \n","    arguments: word, tag label\n","    returns: dictionary with tokens and labels\n","    \"\"\"\n","        \n","    tokens = tokenizer.tokenize(word)\n","    tokenLength = len(tokens)      # find number of tokens corresponfing to word to later add 'X' tokens to labels\n","    \n","    addDict = dict()\n","    \n","    addDict['wordToken'] = tokens\n","    addDict['tagToken'] = [tag] + [tag] * (tokenLength - 1)\n","    addDict['tokenLength'] = tokenLength\n","    \n","    return addDict\n","\n","addWord('10000', 'O')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ojBiEN11sRp6","executionInfo":{"status":"ok","timestamp":1648423506682,"user_tz":420,"elapsed":190,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"6442c1ed-95b0-4fda-9f02-c520785b0219"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'tagToken': ['O', 'O'], 'tokenLength': 2, 'wordToken': ['1000', '##0']}"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["def gen_input(df_words, max_length):\n","\n","  # lists for sentences, tokens, labels, etc.  \n","  sentenceList = []\n","  sentenceTokenList = []\n","  tagTokenList = []\n","  sentLengthList = []\n","\n","  # lists for BERT input\n","  bertSentenceIDs = []\n","  bertMasks = []\n","  bertSequenceIDs = []\n","\n","  sentence = ''\n","\n","  # always start with [CLS] tokens\n","  sentenceTokens = ['[CLS]']\n","  tagTokens = ['[tagCLS]']\n","\n","  prev_par_id = -1\n","\n","  for _, row in df_words.iterrows():\n","\n","    par_id=row[0]\n","    word=row[1]\n","    tag=row[2]\n","\n","    # if new sentence starts\n","    if par_id != prev_par_id:\n","\n","      sentenceLength = min(max_length-1, len(sentenceTokens))\n","      sentLengthList.append(sentenceLength)\n","\n","      # create space for a least a final '[SEP]' token\n","      if sentenceLength >= max_length - 1:\n","        sentenceTokens = sentenceTokens[:max_length-2]\n","        tagTokens = tagTokens[:max_length-2]\n","\n","      # add a [SEP] token and padding\n","      sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length - 1 - len(sentenceTokens))\n","      tagTokens += ['[tagSEP]'] + ['[tagPAD]'] * (max_length - 1 - len(tagTokens))\n","\n","      sentenceList.append(sentence)\n","      sentenceTokenList.append(sentenceTokens)\n","\n","      bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n","      bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length - 1 - sentenceLength))\n","      bertSequenceIDs.append([0] * (max_length))\n","\n","      tagTokenList.append(tagTokens)\n","\n","      sentence = ''\n","      sentenceTokens = ['[CLS]']\n","      tagTokens = ['[tagCLS]']\n","      prev_par_id = par_id\n","\n","      sentence += ' ' + word\n","\n","    addDict = addWord(word, tag)\n","\n","    sentenceTokens += addDict['wordToken']\n","    tagTokens += addDict['tagToken']\n","\n","  # the first list elements need to be removed. \n","  sentLengthList = sentLengthList[1:]\n","  sentenceTokenList = sentenceTokenList[1:]\n","  bertSentenceIDs = bertSentenceIDs[1:]\n","  bertMasks = bertMasks[1:]\n","  bertSequenceIDs = bertSequenceIDs[1:]\n","  tagTokenList = tagTokenList[1:]\n","\n","  return sentLengthList, sentenceTokenList, bertSentenceIDs, bertMasks, bertSequenceIDs, tagTokenList\n","\n"],"metadata":{"id":"K9mMHNLjsV4V","executionInfo":{"status":"ok","timestamp":1648423526796,"user_tz":420,"elapsed":155,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["_, _, trainSentence_ids, trainMasks, trainSequence_ids, tagClasses_train = gen_input(df_words_train, max_length)\n","_, _, testSentence_ids, testMasks, testSequence_ids, tagClasses_test = gen_input(df_words_test, max_length)\n","\n","X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n","X_test = np.array([testSentence_ids,testMasks,testSequence_ids])"],"metadata":{"id":"iqYlB6p3syRO","executionInfo":{"status":"ok","timestamp":1648423564946,"user_tz":420,"elapsed":7937,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["l = ['I', 'O', '[tagCLS]', '[tagPAD]', '[tagSEP]']\n","d = dict([(y,x) for x,y in enumerate(sorted(set(l)))])\n","print(d)\n","\n","tagLabels_train = np.array([[d[y] for y in x] for x in tagClasses_train])\n","tagLabels_test = np.array([[d[y] for y in x] for x in tagClasses_test])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3xt_GKVMs14G","executionInfo":{"status":"ok","timestamp":1648423564946,"user_tz":420,"elapsed":8,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"88f23083-03de-46c2-8a43-3c9e418811f1"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["{'I': 0, 'O': 1, '[tagCLS]': 2, '[tagPAD]': 3, '[tagSEP]': 4}\n"]}]},{"cell_type":"code","source":["# Use a parameter pair k_start, k_end to look at slices. This helps with quick tests.\n","k_start = 0\n","k_end = -1\n","\n","if k_end == -1:\n","    k_end_train = X_train[0].shape[0]\n","    k_end_test = X_test[0].shape[0]\n","else:\n","    k_end_train = k_end_test = k_end\n","    \n","bert_inputs_train_k = [X_train[0][k_start:k_end_train], X_train[1][k_start:k_end_train], \n","                       X_train[2][k_start:k_end_train]]\n","bert_inputs_test_k = [X_test[0][k_start:k_end_test], X_test[1][k_start:k_end_test], \n","                      X_test[2][k_start:k_end_test]]\n","\n","labels_train_k = tagLabels_train[k_start:k_end_train]\n","labels_test_k = tagLabels_test[k_start:k_end_test]\n","\n","train_all = [bert_inputs_train_k, labels_train_k]\n","test_all = [bert_inputs_test_k, labels_test_k]"],"metadata":{"id":"ddPoKFi4s2sB","executionInfo":{"status":"ok","timestamp":1648423923864,"user_tz":420,"elapsed":156,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":["# Baseline Model"],"metadata":{"id":"L5szpVbvl_Tf"}},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","\n","def tokenize_sentences(sentences):\n","\n","  return tokenizer(sentences, \n","                   max_length=max_length,\n","                   truncation=True,\n","                   padding='max_length', \n","                   return_tensors='tf')\n","\n","x_train = tokenize_sentences([str(x) for x in training_set1['text'].values])\n","x_test = tokenize_sentences([str(x) for x in tedf1['text'].values])\n","x_test_s = tokenize_sentences([str(x) for x in dpm.test_set_df['text'].values])\n","\n","y_train = training_set1['label'].values\n","y_test = tedf1['label'].values"],"metadata":{"id":"auffLJkCl-dn","executionInfo":{"status":"ok","timestamp":1648424463589,"user_tz":420,"elapsed":8743,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["try:\n","    del classification_model\n","except:\n","    pass\n","\n","try:\n","    del bert_model\n","except:\n","    pass\n","\n","tf.keras.backend.clear_session()\n","\n","# parameter\n","hidden_size = 256\n","train_layers = -1\n","optimizer = tf.keras.optimizers.Adam(5e-5)\n","\n","# model & layers\n","bert_model = TFBertModel.from_pretrained('bert-base-cased')\n","dense_layer = tf.keras.layers.Dense(hidden_size, name='hidden_layer')\n","cls_layer = tf.keras.layers.Dense(1, activation='sigmoid', name='classification_layer')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y1ZqkS8HmDfX","executionInfo":{"status":"ok","timestamp":1648424465239,"user_tz":420,"elapsed":1653,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"a4681dec-d506-40d6-cf4b-abfefc1808cb"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}]},{"cell_type":"code","source":["input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='input_ids_layer')\n","token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='token_type_ids_layer')\n","attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='attention_mask_layer')\n","\n","bert_inputs = {'input_ids': input_ids,\n","              'token_type_ids': token_type_ids,\n","              'attention_mask': attention_mask}\n","\n","#restrict training to the train_layers outer transformer layers\n","if not train_layers == -1:\n","\n","        retrain_layers = []\n","\n","        for retrain_layer_number in range(train_layers):\n","\n","            layer_code = '_' + str(11 - retrain_layer_number)\n","            retrain_layers.append(layer_code)\n","\n","        for w in bert_model.weights:\n","            if not any([x in w.name for x in retrain_layers]):\n","                w._trainable = False\n","\n","\n","bert_out = bert_model(bert_inputs) #, output_hidden_states=True\n","\n","classification_token = tf.keras.layers.Lambda(lambda x: x[:,0,:], name='get_first_vector')(bert_out[0])\n","dense = dense_layer(classification_token)\n","dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n","classification = cls_layer(dense)\n","\n","classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], \n","                                      outputs=[classification])\n","\n","classification_model.compile(optimizer=optimizer,\n","                        loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n","                        metrics='accuracy')"],"metadata":{"id":"qMm_Sr65mTaP","executionInfo":{"status":"ok","timestamp":1648424466771,"user_tz":420,"elapsed":1535,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["# train\n","for epoch in range(5):\n","  classification_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], y_train,\n","                          epochs=1, batch_size=16)\n","  \n","  y_predict_values = classification_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], \n","                                          batch_size=16, verbose=1)  \n","  \n","  y_predict = [1 if i[0]>0.5 else 0 for i in y_predict_values]\n","  print('Epoch:', epoch+1, 'F1:', f1_score(y_test, y_predict))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lLJ7KGkPmX6b","executionInfo":{"status":"ok","timestamp":1648424616060,"user_tz":420,"elapsed":149292,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"13ff48cd-0da3-4a01-e8cd-89b74a3fcfc9"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["100/100 [==============================] - 29s 134ms/step - loss: 0.5752 - accuracy: 0.7116\n","131/131 [==============================] - 10s 56ms/step\n","Epoch: 1 F1: 0.27474150664697194\n","100/100 [==============================] - 13s 134ms/step - loss: 0.2988 - accuracy: 0.8722\n","131/131 [==============================] - 7s 56ms/step\n","Epoch: 2 F1: 0.40773809523809523\n","100/100 [==============================] - 13s 134ms/step - loss: 0.0844 - accuracy: 0.9723\n","131/131 [==============================] - 7s 56ms/step\n","Epoch: 3 F1: 0.4236453201970443\n","100/100 [==============================] - 13s 134ms/step - loss: 0.0442 - accuracy: 0.9861\n","131/131 [==============================] - 7s 56ms/step\n","Epoch: 4 F1: 0.3956043956043956\n","100/100 [==============================] - 13s 134ms/step - loss: 0.0313 - accuracy: 0.9899\n","131/131 [==============================] - 7s 56ms/step\n","Epoch: 5 F1: 0.3741935483870968\n"]}]},{"cell_type":"markdown","source":["# Span Fine-Tuning"],"metadata":{"id":"nXnndf3SoEdA"}},{"cell_type":"code","source":["numTagClasses = 5\n","\n","def custom_loss(y_true, y_pred):\n","    \"\"\"\n","    calculate loss function explicitly, filtering out 'extra inserted labels'\n","    \n","    y_true: Shape: (batch x (max_length + 1) )\n","    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n","    \n","    returns:  cost\n","    \"\"\"\n","\n","    #get labels and predictions\n","    y_label = tf.reshape(Flatten()(tf.cast(y_true, tf.int32)),[-1])\n","    \n","    mask = (y_label < 2)   # This mask is used to remove all tokens that do not correspond to the original base text.\n","\n","    y_label_masked = tf.boolean_mask(y_label, mask)  # mask the labels\n","    \n","    y_flat_pred = tf.reshape(Flatten()(tf.cast(y_pred, tf.float32)),[-1, numTagClasses])\n","    \n","    y_flat_pred_masked = tf.boolean_mask(y_flat_pred, mask) # mask the predictions\n","    \n","    return tf.reduce_mean(sparse_categorical_crossentropy(y_label_masked, y_flat_pred_masked,from_logits=False ))\n","\n","#\n","def custom_acc_orig_tokens(y_true, y_pred):\n","    \"\"\"\n","    calculate loss dfunction filtering out also the newly inserted labels\n","    \n","    y_true: Shape: (batch x (max_length) )\n","    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n","    \n","    returns: accuracy\n","    \"\"\"\n","\n","    #get labels and predictions\n","    \n","    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n","    \n","    mask = (y_label < 2)\n","    y_label_masked = tf.boolean_mask(y_label, mask)\n","    \n","    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n","                                                    [-1, numTagClasses]), axis=1)\n","    \n","    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n","\n","    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"],"metadata":{"id":"-Xx4ADM7noQp","executionInfo":{"status":"ok","timestamp":1648425211513,"user_tz":420,"elapsed":2,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["try:\n","    del classification_model\n","except:\n","    pass\n","\n","try:\n","    del bert_model\n","except:\n","    pass\n","\n","tf.keras.backend.clear_session()\n","\n","bert_layer_span = TFBertModel.from_pretrained('bert-base-cased')\n","adam_customized = tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.91, beta_2=0.999, epsilon=None, decay=0.1, amsgrad=False)\n","\n","max_input_length = max_length + 1\n","train_layers = -1\n","optimizer = adam_customized\n","\n","in_id = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_ids\")\n","in_mask = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_masks\")\n","in_segment = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"segment_ids\")\n","bert_inputs = [in_id, in_mask, in_segment]\n","\n","# Note: Bert layer from Hugging Face returns two values: sequence ouput, and pooled output. Here, we only want\n","# the former. (See https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel) \n","\n","# Freeze layers, i.e. only train number of layers specified, starting from the top\n","if not train_layers == -1:\n","    retrain_layers = []\n","    for retrain_layer_number in range(train_layers):\n","        layer_code = '_' + str(11 - retrain_layer_number)\n","        retrain_layers.append(layer_code)\n","    for w in bert_layer_span.weights:\n","        if not any([x in w.name for x in retrain_layers]):\n","            w._trainable = False\n","# End of freezing section\n","\n","bert_sequence = bert_layer_span(bert_inputs)[0]\n","dense = tf.keras.layers.Dense(256, activation='relu', name='dense')(bert_sequence)\n","dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n","pred = tf.keras.layers.Dense(5, activation='softmax', name='tag')(dense)\n","\n","## Prepare for multipe loss functions, although not used here\n","losses = {\"tag\": custom_loss,}\n","lossWeights = {\"tag\": 1.0}\n","\n","model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n","model.compile(loss=losses, optimizer=optimizer, metrics=[custom_acc_orig_tokens])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eVbDVZY0tiic","executionInfo":{"status":"ok","timestamp":1648425217647,"user_tz":420,"elapsed":5436,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"1581aa0e-41c1-4ce9-fe89-84bd54deb694"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["model.fit(\n","    bert_inputs_train_k, \n","    {\"tag\": labels_train_k },\n","    validation_data=(bert_inputs_test_k, {\"tag\": labels_test_k }),\n","    epochs=1,\n","    batch_size=16\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3TSWoMp8t5ht","executionInfo":{"status":"ok","timestamp":1648425258927,"user_tz":420,"elapsed":41287,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"9a9e6bd0-820d-46d0-ecac-3c3a8fa46220"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","50/50 [==============================] - 34s 207ms/step - loss: 0.7560 - custom_acc_orig_tokens: 0.6119 - val_loss: 0.6239 - val_custom_acc_orig_tokens: 0.6410\n","Epoch 2/2\n","50/50 [==============================] - 7s 149ms/step - loss: 0.5406 - custom_acc_orig_tokens: 0.7283 - val_loss: 0.5075 - val_custom_acc_orig_tokens: 0.7486\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f26b9488890>"]},"metadata":{},"execution_count":76}]},{"cell_type":"markdown","source":["# CLS Model"],"metadata":{"id":"j6QsUxCxuda8"}},{"cell_type":"code","source":["#tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","\n","def tokenize_sentences(sentences):\n","\n","  return tokenizer(sentences, \n","                   max_length=max_length,\n","                   truncation=True,\n","                   padding='max_length', \n","                   return_tensors='tf')\n","\n","x_train = tokenize_sentences([str(x) for x in training_set1['text'].values])\n","x_test = tokenize_sentences([str(x) for x in tedf1['text'].values])\n","x_test_s = tokenize_sentences([str(x) for x in dpm.test_set_df['text'].values])\n","\n","y_train = training_set1['label'].values\n","y_test = tedf1['label'].values"],"metadata":{"id":"y5sFqmNyufHz","executionInfo":{"status":"ok","timestamp":1648425266300,"user_tz":420,"elapsed":7232,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["# parameter\n","hidden_size = 256\n","train_layers = -1\n","optimizer = tf.keras.optimizers.Adam(5e-5)\n","\n","# model & layers\n","dense_layer = tf.keras.layers.Dense(hidden_size, name='hidden_layer')\n","cls_layer = tf.keras.layers.Dense(1, activation='sigmoid', name='classification_layer')"],"metadata":{"id":"W6929VEFuocm","executionInfo":{"status":"ok","timestamp":1648425266300,"user_tz":420,"elapsed":19,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='input_ids_layer')\n","token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='token_type_ids_layer')\n","attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='attention_mask_layer')\n","\n","bert_inputs = {'input_ids': input_ids,\n","              'token_type_ids': token_type_ids,\n","              'attention_mask': attention_mask}\n","\n","#restrict training to the train_layers outer transformer layers\n","if not train_layers == -1:\n","\n","        retrain_layers = []\n","\n","        for retrain_layer_number in range(train_layers):\n","\n","            layer_code = '_' + str(11 - retrain_layer_number)\n","            retrain_layers.append(layer_code)\n","\n","        for w in bert_model.weights:\n","            if not any([x in w.name for x in retrain_layers]):\n","                w._trainable = False\n","\n","\n","bert_out = bert_layer_span(bert_inputs) #, output_hidden_states=True\n","\n","classification_token = tf.keras.layers.Lambda(lambda x: x[:,0,:], name='get_first_vector')(bert_out[0])\n","dense = dense_layer(classification_token)\n","dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n","classification = cls_layer(dense)\n","\n","classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], \n","                                      outputs=[classification])\n","\n","classification_model.compile(optimizer=optimizer,\n","                        loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n","                        metrics='accuracy')"],"metadata":{"id":"T9yELJ88u4bi","executionInfo":{"status":"ok","timestamp":1648425267729,"user_tz":420,"elapsed":1447,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["# train\n","for epoch in range(5):\n","  classification_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], y_train,\n","                          epochs=1, batch_size=16)\n","  \n","  y_predict_values = classification_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], \n","                                          batch_size=16, verbose=1)  \n","  \n","  y_predict = [1 if i[0]>0.5 else 0 for i in y_predict_values]\n","  print('Epoch:', epoch+1, 'F1:', f1_score(y_test, y_predict))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRImlgGMu-Hp","executionInfo":{"status":"ok","timestamp":1648425429448,"user_tz":420,"elapsed":161723,"user":{"displayName":"Thomas Gao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5Wy7q7Whr7AU8nPmSyo80xni6pBoRAbGFSezRGQ=s64","userId":"14530139701852982005"}},"outputId":"4770470d-be2e-4ef0-a7df-80774cb6b008"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["100/100 [==============================] - 28s 134ms/step - loss: 0.6328 - accuracy: 0.6625\n","131/131 [==============================] - 10s 57ms/step\n","Epoch: 1 F1: 0.39209225700164746\n","100/100 [==============================] - 13s 135ms/step - loss: 0.4873 - accuracy: 0.7890\n","131/131 [==============================] - 7s 56ms/step\n","Epoch: 2 F1: 0.4081632653061224\n","100/100 [==============================] - 13s 134ms/step - loss: 0.2945 - accuracy: 0.8892\n","131/131 [==============================] - 7s 56ms/step\n","Epoch: 3 F1: 0.3051146384479718\n","100/100 [==============================] - 13s 134ms/step - loss: 0.2198 - accuracy: 0.9276\n","131/131 [==============================] - 7s 56ms/step\n","Epoch: 4 F1: 0.34994462901439644\n","100/100 [==============================] - 13s 134ms/step - loss: 0.0779 - accuracy: 0.9767\n","131/131 [==============================] - 7s 56ms/step\n","Epoch: 5 F1: 0.39926062846580407\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"6rKyL03dvHzm"},"execution_count":null,"outputs":[]}]}